{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages*+--\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import mne\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from keras.layers import (LSTM, Activation, BatchNormalization, Conv2D, Dense,\n",
    "                          Dropout, Flatten, Reshape)\n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (LSTM, Activation, BatchNormalization,\n",
    "                                     Conv2D, Dense, Dropout, Flatten, Reshape)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "os.chdir('D:/EEG-ESRT/datasets/EEGMMIDB/')\n",
    "\n",
    "SList = ['%03d' % i for i in range(1, 110)]\n",
    "RList = ['%02d' % i for i in range(1, 15)]\n",
    "Lists = []\n",
    "for j in SList:\n",
    "    name = 's' + str(j)\n",
    "    name = np.zeros((64, 160))\n",
    "    name = np.expand_dims(name, axis=0)\n",
    "    for i in RList:\n",
    "        file = os.getcwd() + '/S' + str(j) + '/S' + str(j) + 'R' + str(\n",
    "            i) + '.edf'\n",
    "        data = mne.io.read_raw_edf(file)\n",
    "        raw_data = data.get_data()\n",
    "\n",
    "        # 1 sec parts\n",
    "        for k in range(int((np.size(raw_data, 1)) / 160)):\n",
    "            name = np.concatenate(\n",
    "                (name,\n",
    "                 np.expand_dims(raw_data[:, (k) * 160:(k + 1) * 160], axis=0)),\n",
    "                axis=0)\n",
    "\n",
    "        # free up memory\n",
    "        path = []\n",
    "        cwd = os.getcwd()\n",
    "        file = os.getcwd() + '/S' + str(j) + '/S' + str(j) + 'R' + str(\n",
    "            i) + '.edf'\n",
    "        path.append(os.path.join(cwd, file))\n",
    "        os.remove(path[0])\n",
    "    name = name[1:np.size(name, 0), :, :]\n",
    "    subj = 'S' + str(j)\n",
    "    np.save(subj, name)\n",
    "\n",
    "# Selecting Channels\n",
    "SList = ['%03d' % i for i in range(1, 110)]\n",
    "RList = ['%02d' % i for i in range(1, 15)]\n",
    "\n",
    "# For 32 Channels\n",
    "channels32 = [\n",
    "    0, 2, 3, 4, 6, 8, 10, 12, 14, 16, 17, 18, 20, 21, 22, 23, 26, 29, 31, 33,\n",
    "    35, 37, 40, 41, 46, 48, 50, 52, 54, 57, 60, 62\n",
    "]\n",
    "for j in SList:\n",
    "    name = 'S' + str(j) + '.npy'\n",
    "    a = np.load(name)\n",
    "    a = a[:, channels32, :]\n",
    "    subject = 's' + str(j)\n",
    "    np.save(subject, a)\n",
    "\n",
    "# Assigning p% of data for training\n",
    "SList = ['%03d' % i for i in range(1, 110)]\n",
    "RList = ['%02d' % i for i in range(1, 15)]\n",
    "p = 0.9\n",
    "for j in SList:\n",
    "    name = 's' + str(j) + '.npy'\n",
    "    a = np.load(name)\n",
    "    shuffle = list(range(np.size(a, 0)))\n",
    "    np.random.shuffle(shuffle)\n",
    "    a = a[shuffle, :, :]\n",
    "    num_tr = int(p * np.size(a, 0))\n",
    "    x_tr = a[0:num_tr, :, :]\n",
    "    x_te = a[num_tr + 1:np.size(a, 0), :, :]\n",
    "    subject_tr = 's' + str(j) + '_train'\n",
    "    subject_te = 's' + str(j) + '_test'\n",
    "    np.save(subject_tr, x_tr)\n",
    "    np.save(subject_te, x_te)\n",
    "    print(j)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "SList = ['%03d' % i for i in range(1, 110)]\n",
    "RList = ['%02d' % i for i in range(1, 15)]\n",
    "\n",
    "# note that n_ch should be equal to what you selected in channel selection step!\n",
    "# here we chose 4\n",
    "n_ch = 32\n",
    "y_train = np.zeros((1, 1))\n",
    "x_train = np.zeros((1, n_ch, 160))\n",
    "print('Train Dataset----------------------------------')\n",
    "for j in tqdm(SList):\n",
    "    name = 's' + str(j) + '_train.npy'\n",
    "    a = np.load(name)\n",
    "    #print(a.shape)\n",
    "    x_train = np.concatenate((x_train, a), axis=0)\n",
    "    y = (int(j) - 1) * np.ones((np.size(a, 0), 1))\n",
    "    y_train = np.concatenate((y_train, y))\n",
    "    # print(j)\n",
    "    del a\n",
    "    del y\n",
    "\n",
    "print('Test Dataset----------------------------------')\n",
    "# note that n_ch should be equal to what you selected in channel selection step!\n",
    "# here we chose 4\n",
    "y_test = np.zeros((1, 1))\n",
    "x_test = np.zeros((1, n_ch, 160))\n",
    "for j in tqdm(SList):\n",
    "    name = 's' + str(j) + '_test.npy'\n",
    "    a = np.load(name)\n",
    "    x_test = np.concatenate((x_test, a), axis=0)\n",
    "    y = (int(j) - 1) * np.ones((np.size(a, 0), 1))\n",
    "    y_test = np.concatenate((y_test, y))\n",
    "    # print(j)\n",
    "    del a\n",
    "    del y\n",
    "\n",
    "# deleting one unwanted index\n",
    "x_train = x_train[1:np.size(x_train, 0), :, :]\n",
    "x_test = x_test[1:np.size(x_test, 0), :, :]\n",
    "y_train = y_train[1:np.size(y_train, 0), :]\n",
    "y_test = y_test[1:np.size(y_test, 0), :]\n",
    "\n",
    "# data shape\n",
    "print('Shape of x_train:', np.shape(x_train))\n",
    "print('Shape of x_test:', np.shape(x_test))\n",
    "print('Shape of y_train:', np.shape(y_train))\n",
    "print('Shape of y_test:', np.shape(y_test))\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "print('Input shape:', input_shape)\n",
    "\n",
    "# normalizing your data\n",
    "maxMat = np.amax(x_train, axis=0, keepdims=True)\n",
    "x_train = np.divide(x_train, maxMat)\n",
    "x_test = np.divide(x_test, maxMat)\n",
    "del maxMat\n",
    "\n",
    "# shuffling data\n",
    "shuffle = list(range(np.size(x_train, 0)))\n",
    "np.random.shuffle(shuffle)\n",
    "x_train = x_train[shuffle, :, :]\n",
    "y_train = y_train[shuffle, ]\n",
    "\n",
    "shuffle = list(range(np.size(x_test, 0)))\n",
    "np.random.shuffle(shuffle)\n",
    "x_test = x_test[shuffle, :, :]\n",
    "y_test = y_test[shuffle, ]\n",
    "\n",
    "print('Shape of x_train after shuffling:', np.shape(x_train))\n",
    "print('Shape of x_test after shuffling:', np.shape(x_test))\n",
    "print('Shape of y_train after shuffling:', np.shape(y_train))\n",
    "print('Shape of y_test after shuffling:', np.shape(y_test))\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "print('Input shape after shuffling:', input_shape)\n",
    "\n",
    "del shuffle\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2],\n",
    "                          1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "num_classes = 109\n",
    "y_train = np.reshape(y_train, [\n",
    "    np.size(y_train, 0),\n",
    "])\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = np.reshape(y_test, [\n",
    "    np.size(y_test, 0),\n",
    "])\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print('Shape of x_train after reshaping:', np.shape(x_train))\n",
    "print('Shape of x_test after reshaping:', np.shape(x_test))\n",
    "print('Shape of y_train after reshaping:', np.shape(y_train))\n",
    "print('Shape of y_test after reshaping:', np.shape(y_test))\n",
    "input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "print('Input shape after reshaping:', input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#layer1\n",
    "model.add(\n",
    "    Conv2D(128,\n",
    "           kernel_size=(n_ch, 1),\n",
    "           padding='valid',\n",
    "           input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(\n",
    "    Reshape(\n",
    "        (model.output_shape[3], model.output_shape[2], model.output_shape[1])))\n",
    "\n",
    "## Layer 2\n",
    "model.add(Conv2D(256, kernel_size=(128, 1), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(\n",
    "    Reshape(\n",
    "        (model.output_shape[3], model.output_shape[2], model.output_shape[1])))\n",
    "\n",
    "## Layer 3\n",
    "model.add(Conv2D(512, kernel_size=(256, 1), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(\n",
    "    Reshape(\n",
    "        (model.output_shape[3], model.output_shape[2], model.output_shape[1])))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=lr,\n",
    "                                                        decay=decay),\n",
    "              metrics=['accuracy', 'FalsePositives', 'FalseNegatives'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tensorboard_callback, checkpoint_callback],\n",
    "                    initial_epoch=initial_epoch)\n",
    "\n",
    "# Save the final model\n",
    "model.save(final_model_path)\n",
    "\n",
    "# Evaluate the model\n",
    "score_train = model.evaluate(x_train, y_train, verbose=0)\n",
    "score_test = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('mean train accuracy is:   ', (score_train[1]))\n",
    "print('mean test accuracy is:   ', (score_test[1]))\n",
    "print('FAR is:   ', (score_train[2] + score_test[2]) /\n",
    "      (np.size(y_train, 0) + np.size(y_test, 0)))\n",
    "print('FRR is:   ', (score_train[3] + score_test[3]) /\n",
    "      (np.size(y_train, 0) + np.size(y_test, 0)))\n",
    "\n",
    "# Plot and save accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.savefig(acc_plot_path, dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Plot and save loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.savefig(loss_plot_path, dpi=600)\n",
    "plt.show()\n",
    "# Save history data to a JSON file\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
